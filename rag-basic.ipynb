{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install llama-hub\n!pip install -U pydantic\n!pip install llama-cpp-python llama-index chromadb sentence_transformers pymupdf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom llama_hub.file.pymu_pdf.base import PyMuPDFReader","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:01.301521Z","iopub.execute_input":"2024-01-21T15:45:01.301838Z","iopub.status.idle":"2024-01-21T15:45:04.954552Z","shell.execute_reply.started":"2024-01-21T15:45:01.301809Z","shell.execute_reply":"2024-01-21T15:45:04.953684Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# sentence transformers\nfrom llama_index.embeddings import HuggingFaceEmbedding\n\nembed_model = HuggingFaceEmbedding(model_name=\"jinaai/jina-embeddings-v2-base-en\")","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:04.955676Z","iopub.execute_input":"2024-01-21T15:45:04.956181Z","iopub.status.idle":"2024-01-21T15:45:15.077914Z","shell.execute_reply.started":"2024-01-21T15:45:04.956127Z","shell.execute_reply":"2024-01-21T15:45:15.076744Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dde52e1514654027b71d9f881075a617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/275M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"024769b21eea4cfb8b58787e1e3689bf"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-en and are newly initialized: ['encoder.layer.3.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b254b0f730c40769c8727c5d1a91be3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d67269ca8f294b6ba4513a22f45e5337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"000eabbe7e9f49a9b5027a3b8d8deef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"696016febfa849119738b6c5c858bc05"}},"metadata":{}}]},{"cell_type":"code","source":"from llama_index.llms import LlamaCPP\n\nmodel_url = \"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf\"\n\nllm = LlamaCPP(\n    model_url = model_url,\n    temperature = 0.3,\n    max_new_tokens = 256,\n    context_window = 3900,\n    generate_kwargs = {},\n    model_kwargs = {\"n_gpu_layers\": 5},\n    verbose = True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:15.079470Z","iopub.execute_input":"2024-01-21T15:45:15.080629Z","iopub.status.idle":"2024-01-21T15:45:39.034418Z","shell.execute_reply.started":"2024-01-21T15:45:15.080588Z","shell.execute_reply":"2024-01-21T15:45:39.032701Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading url https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf to path /tmp/llama_index/models/llama-2-13b-chat.Q4_0.gguf\ntotal size (MB): 7365.83\n","output_type":"stream"},{"name":"stderr","text":"7025it [00:21, 332.89it/s]                          \nllama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /tmp/llama_index/models/llama-2-13b-chat.Q4_0.gguf (version GGUF V2)\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = LLaMA v2\nllama_model_loader: - kv   2:                       llama.context_length u32              = 4096\nllama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\nllama_model_loader: - kv   4:                          llama.block_count u32              = 40\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  10:                          general.file_type u32              = 2\nllama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\nllama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\nllama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\nllama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\nllama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\nllama_model_loader: - kv  18:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   81 tensors\nllama_model_loader: - type q4_0:  281 tensors\nllama_model_loader: - type q6_K:    1 tensors\nllm_load_vocab: special tokens definition check successful ( 259/32000 ).\nllm_load_print_meta: format           = GGUF V2\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = SPM\nllm_load_print_meta: n_vocab          = 32000\nllm_load_print_meta: n_merges         = 0\nllm_load_print_meta: n_ctx_train      = 4096\nllm_load_print_meta: n_embd           = 5120\nllm_load_print_meta: n_head           = 40\nllm_load_print_meta: n_head_kv        = 40\nllm_load_print_meta: n_layer          = 40\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 1\nllm_load_print_meta: n_embd_k_gqa     = 5120\nllm_load_print_meta: n_embd_v_gqa     = 5120\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: n_ff             = 13824\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 10000.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_yarn_orig_ctx  = 4096\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: model type       = 13B\nllm_load_print_meta: model ftype      = Q4_0\nllm_load_print_meta: model params     = 13.02 B\nllm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \nllm_load_print_meta: general.name     = LLaMA v2\nllm_load_print_meta: BOS token        = 1 '<s>'\nllm_load_print_meta: EOS token        = 2 '</s>'\nllm_load_print_meta: UNK token        = 0 '<unk>'\nllm_load_print_meta: LF token         = 13 '<0x0A>'\nllm_load_tensors: ggml ctx size =    0.14 MiB\nllm_load_tensors: offloading 5 repeating layers to GPU\nllm_load_tensors: offloaded 5/41 layers to GPU\nllm_load_tensors:        CPU buffer size =  7023.90 MiB\n...................................................................................................\nllama_new_context_with_model: n_ctx      = 3900\nllama_new_context_with_model: freq_base  = 10000.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:        CPU KV buffer size =  3046.88 MiB\nllama_new_context_with_model: KV self size  = 3046.88 MiB, K (f16): 1523.44 MiB, V (f16): 1523.44 MiB\nllama_new_context_with_model: graph splits (measure): 1\nllama_new_context_with_model:        CPU compute buffer size =   342.31 MiB\nAVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index import ServiceContext\n\nservice_context = ServiceContext.from_defaults(\n    llm =llm, embed_model=embed_model\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:39.038169Z","iopub.execute_input":"2024-01-21T15:45:39.038738Z","iopub.status.idle":"2024-01-21T15:45:39.628540Z","shell.execute_reply.started":"2024-01-21T15:45:39.038709Z","shell.execute_reply":"2024-01-21T15:45:39.627482Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import chromadb\nfrom llama_index.vector_stores import ChromaVectorStore\nfrom llama_index.storage.storage_context import StorageContext\n\n# initialize client, setting path to save data\ndb = chromadb.PersistentClient(path=\"./chroma_db\")\n\n# create collection\nchroma_collection = db.get_or_create_collection(\"quickstart\")\n\n# assign chroma as the vector_store to the context\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:46:47.650802Z","iopub.execute_input":"2024-01-21T15:46:47.651818Z","iopub.status.idle":"2024-01-21T15:46:49.027953Z","shell.execute_reply.started":"2024-01-21T15:46:47.651777Z","shell.execute_reply":"2024-01-21T15:46:49.027067Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!mkdir data\n!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\"","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:46:51.129016Z","iopub.execute_input":"2024-01-21T15:46:51.129629Z","iopub.status.idle":"2024-01-21T15:46:53.306318Z","shell.execute_reply.started":"2024-01-21T15:46:51.129599Z","shell.execute_reply":"2024-01-21T15:46:53.305215Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'data': File exists\n--2024-01-21 15:46:53--  https://arxiv.org/pdf/2307.09288.pdf\nResolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.67.42, 151.101.195.42, ...\nConnecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 13661300 (13M) [application/pdf]\nSaving to: 'data/llama2.pdf'\n\ndata/llama2.pdf     100%[===================>]  13.03M  --.-KB/s    in 0.06s   \n\n2024-01-21 15:46:53 (226 MB/s) - 'data/llama2.pdf' saved [13661300/13661300]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"loader = PyMuPDFReader()\ndocuments = loader.load(file_path=\"data/llama2.pdf\")","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:46:58.682930Z","iopub.execute_input":"2024-01-21T15:46:58.683383Z","iopub.status.idle":"2024-01-21T15:46:59.874428Z","shell.execute_reply.started":"2024-01-21T15:46:58.683346Z","shell.execute_reply":"2024-01-21T15:46:59.873587Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from llama_index.node_parser.text import SentenceSplitter","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:47:01.609536Z","iopub.execute_input":"2024-01-21T15:47:01.609961Z","iopub.status.idle":"2024-01-21T15:47:01.614713Z","shell.execute_reply.started":"2024-01-21T15:47:01.609921Z","shell.execute_reply":"2024-01-21T15:47:01.613629Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"text_parser = SentenceSplitter(\n    chunk_size=1024,\n    separator=\".\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:47:02.824762Z","iopub.execute_input":"2024-01-21T15:47:02.825440Z","iopub.status.idle":"2024-01-21T15:47:02.829956Z","shell.execute_reply.started":"2024-01-21T15:47:02.825409Z","shell.execute_reply":"2024-01-21T15:47:02.828928Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"text_chunks = []\n# maintain relationship with source doc index, to help inject doc metadata in (3)\ndoc_idxs = []\nfor doc_idx, doc in enumerate(documents):\n    cur_text_chunks = text_parser.split_text(doc.text)\n    text_chunks.extend(cur_text_chunks)\n    doc_idxs.extend([doc_idx] * len(cur_text_chunks))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:47:04.609834Z","iopub.execute_input":"2024-01-21T15:47:04.610739Z","iopub.status.idle":"2024-01-21T15:47:04.950825Z","shell.execute_reply.started":"2024-01-21T15:47:04.610703Z","shell.execute_reply":"2024-01-21T15:47:04.949860Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from llama_index.schema import TextNode\n\nnodes = []\nfor idx, text_chunk in enumerate(text_chunks):\n    node = TextNode(\n        text=text_chunk,\n    )\n    src_doc = documents[doc_idxs[idx]]\n    node.metadata = src_doc.metadata\n    nodes.append(node)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:47:06.705201Z","iopub.execute_input":"2024-01-21T15:47:06.706052Z","iopub.status.idle":"2024-01-21T15:47:06.722705Z","shell.execute_reply.started":"2024-01-21T15:47:06.706013Z","shell.execute_reply":"2024-01-21T15:47:06.721959Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for node in nodes:\n    node_embedding = embed_model.get_text_embedding(\n        node.get_content(metadata_mode=\"all\")\n    )\n    node.embedding = node_embedding","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:47:08.720471Z","iopub.execute_input":"2024-01-21T15:47:08.720823Z","iopub.status.idle":"2024-01-21T15:47:13.371987Z","shell.execute_reply.started":"2024-01-21T15:47:08.720798Z","shell.execute_reply":"2024-01-21T15:47:13.370967Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"vector_store.add(nodes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_str = \"Can you tell me about the key concepts for safety finetuning\"","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:47:13.994754Z","iopub.status.idle":"2024-01-21T15:47:13.995077Z","shell.execute_reply.started":"2024-01-21T15:47:13.994919Z","shell.execute_reply":"2024-01-21T15:47:13.994934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_embedding = embed_model.get_query_embedding(query_str)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.691665Z","iopub.status.idle":"2024-01-21T15:45:41.692332Z","shell.execute_reply.started":"2024-01-21T15:45:41.692130Z","shell.execute_reply":"2024-01-21T15:45:41.692169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llama_index.vector_stores import VectorStoreQuery\n\nquery_mode = \"default\"\n# query_mode = \"sparse\"\n# query_mode = \"hybrid\"\n\nvector_store_query = VectorStoreQuery(\n    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.693551Z","iopub.status.idle":"2024-01-21T15:45:41.694329Z","shell.execute_reply.started":"2024-01-21T15:45:41.694099Z","shell.execute_reply":"2024-01-21T15:45:41.694124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# returns a VectorStoreQueryResult\nquery_result = vector_store.query(vector_store_query)\nprint(query_result.nodes[0].get_content())","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.695479Z","iopub.status.idle":"2024-01-21T15:45:41.695888Z","shell.execute_reply.started":"2024-01-21T15:45:41.695712Z","shell.execute_reply":"2024-01-21T15:45:41.695732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llama_index.schema import NodeWithScore\nfrom typing import Optional\n\nnodes_with_scores = []\nfor index, node in enumerate(query_result.nodes):\n    score: Optional[float] = None\n    if query_result.similarities is not None:\n        score = query_result.similarities[index]\n    nodes_with_scores.append(NodeWithScore(node=node, score=score))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.697058Z","iopub.status.idle":"2024-01-21T15:45:41.698003Z","shell.execute_reply.started":"2024-01-21T15:45:41.697827Z","shell.execute_reply":"2024-01-21T15:45:41.697847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llama_index import QueryBundle\nfrom llama_index.retrievers import BaseRetriever\nfrom typing import Any, List\n\n\nclass VectorDBRetriever(BaseRetriever):\n    \"\"\"Retriever over a postgres vector store.\"\"\"\n\n    def __init__(\n        self,\n        vector_store: ChromaVectorStore,\n        embed_model: Any,\n        query_mode: str = \"default\",\n        similarity_top_k: int = 2,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        self._vector_store = vector_store\n        self._embed_model = embed_model\n        self._query_mode = query_mode\n        self._similarity_top_k = similarity_top_k\n        super().__init__()\n\n    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n        \"\"\"Retrieve.\"\"\"\n        query_embedding = embed_model.get_query_embedding(\n            query_bundle.query_str\n        )\n        vector_store_query = VectorStoreQuery(\n            query_embedding=query_embedding,\n            similarity_top_k=self._similarity_top_k,\n            mode=self._query_mode,\n        )\n        query_result = vector_store.query(vector_store_query)\n\n        nodes_with_scores = []\n        for index, node in enumerate(query_result.nodes):\n            score: Optional[float] = None\n            if query_result.similarities is not None:\n                score = query_result.similarities[index]\n            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n\n        return nodes_with_scores","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.699542Z","iopub.status.idle":"2024-01-21T15:45:41.700620Z","shell.execute_reply.started":"2024-01-21T15:45:41.700293Z","shell.execute_reply":"2024-01-21T15:45:41.700319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retriever = VectorDBRetriever(\n    vector_store, embed_model, query_mode=\"default\", similarity_top_k=2\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.702184Z","iopub.status.idle":"2024-01-21T15:45:41.702692Z","shell.execute_reply.started":"2024-01-21T15:45:41.702420Z","shell.execute_reply":"2024-01-21T15:45:41.702443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llama_index.query_engine import RetrieverQueryEngine\n\nquery_engine = RetrieverQueryEngine.from_args(\n    retriever, service_context=service_context\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.704313Z","iopub.status.idle":"2024-01-21T15:45:41.704718Z","shell.execute_reply.started":"2024-01-21T15:45:41.704484Z","shell.execute_reply":"2024-01-21T15:45:41.704500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_str = \"How does Llama 2 perform compared to other open-source models?\"\n\nresponse = query_engine.query(query_str)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.705686Z","iopub.status.idle":"2024-01-21T15:45:41.706033Z","shell.execute_reply.started":"2024-01-21T15:45:41.705845Z","shell.execute_reply":"2024-01-21T15:45:41.705861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(str(response))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:45:41.707546Z","iopub.status.idle":"2024-01-21T15:45:41.707928Z","shell.execute_reply.started":"2024-01-21T15:45:41.707758Z","shell.execute_reply":"2024-01-21T15:45:41.707778Z"},"trusted":true},"execution_count":null,"outputs":[]}]}